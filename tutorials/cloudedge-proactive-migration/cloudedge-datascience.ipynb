{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e5060d8-025f-45c6-9d8b-be1bf425daa8",
   "metadata": {},
   "source": [
    "# CloudEdge DataScience Team (Training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd00b57",
   "metadata": {},
   "source": [
    "## Architecture\n",
    "\n",
    "Make sure to set these environment variables in your session with the proper values. All of them are mandatory except:\n",
    "- `DOCKER_REGISTRY`: if you plan to push the images to a private registry\n",
    "- `DOCKER_TAG`: if you don't want to leave the default `latest` tag\n",
    "- `DOCKER_REGISTRY_USERNAME`: if your private registry requires authentication\n",
    "- `DOCKER_REGISTRY_PASSWORD`: if your private registry requires authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec4ef2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WORKDIR=/home/jolivera/Documents/CloudSkin/Scanflow/data-connector\n",
      "env: KUBECONFIG_PATH=/home/jolivera/.kube/config_ncloud_socat\n",
      "env: PROACTIVE_MIGRATION_DATASCIENCE_APP_DIR=examples/cloudedge-proactive-migration/datascience\n",
      "env: SCANFLOW_SERVER_URI=http://84.88.189.179:32767\n",
      "env: SCANFLOW_TRACKER_URI=http://84.88.189.179:32766\n",
      "env: MLFLOW_S3_ENDPOINT_URL=http://84.88.189.179:32645\n",
      "env: SCANFLOW_TRACKER_STORAGE=postgresql://postgres:scanflow123@scanflow-postgres.scanflow-server.svc.cluster.local/scanflow-cloudedge-datascience\n",
      "env: AWS_ACCESS_KEY_ID=scanflow\n",
      "env: AWS_SECRET_ACCESS_KEY=scanflow123\n",
      "env: DOCKER_REGISTRY=registry.gitlab.bsc.es/datacentric-computing/cloudskin-project/cloudskin-registry\n",
      "env: DOCKER_TAG=feat/proactive-migration\n",
      "env: DOCKER_REGISTRY_USERNAME=cloudskin-scanflow-builds\n",
      "env: DOCKER_REGISTRY_PASSWORD=ii6c4bvSp58yzhckoyBA\n",
      "env: SCANFLOW_APP_NAME=cloudedge-proactive-migration-experiment\n",
      "env: SCANFLOW_TEAM_NAME=datascience\n",
      "env: NBY_SERVICE_NAME=dlstreamer-pipeline-server\n",
      "env: NBY_ORGANIZATION_ID=abcd-1234-uvxyz-9876\n",
      "env: NBY_ENV_NAME=nearbyone.innovationlab\n",
      "env: NBY_ENV_EMAIL=fake.username@example.com\n",
      "env: NBY_ENV_PASSWORD=fake-password\n",
      "env: LOCAL_DEPLOY=1\n"
     ]
    }
   ],
   "source": [
    "# Only for debug purposes, don't leave them enable in the repository!!!\n",
    "%env WORKDIR=/home/jolivera/Documents/CloudSkin/Scanflow/data-connector\n",
    "%env KUBECONFIG_PATH=/home/jolivera/.kube/config_ncloud_socat\n",
    "%env PROACTIVE_MIGRATION_DATASCIENCE_APP_DIR=examples/cloudedge-proactive-migration/datascience\n",
    "%env SCANFLOW_SERVER_URI=http://84.88.189.179:32767\n",
    "%env SCANFLOW_TRACKER_URI=http://84.88.189.179:32766\n",
    "%env MLFLOW_S3_ENDPOINT_URL=http://84.88.189.179:32645\n",
    "# PostgreSQL URI with credentials\n",
    "%env SCANFLOW_TRACKER_STORAGE=postgresql://postgres:scanflow123@scanflow-postgres.scanflow-server.svc.cluster.local/scanflow-cloudedge-datascience\n",
    "# MinIO API endpoint, not console!\n",
    "%env AWS_ACCESS_KEY_ID=scanflow\n",
    "%env AWS_SECRET_ACCESS_KEY=scanflow123\n",
    "%env DOCKER_REGISTRY=registry.gitlab.bsc.es/datacentric-computing/cloudskin-project/cloudskin-registry\n",
    "# If you use invalid characters for a tag, Scanflow will replace them with '-'\n",
    "%env DOCKER_TAG=feat/proactive-migration\n",
    "%env DOCKER_REGISTRY_USERNAME=cloudskin-scanflow-builds\n",
    "%env DOCKER_REGISTRY_PASSWORD=ii6c4bvSp58yzhckoyBA\n",
    "%env SCANFLOW_APP_NAME=cloudedge-proactive-migration-experiment\n",
    "%env SCANFLOW_TEAM_NAME=datascience\n",
    "# NEARBYONE CONTROLLER VARIABLES\n",
    "%env NBY_SERVICE_NAME=dlstreamer-pipeline-server\n",
    "%env NBY_ORGANIZATION_ID=abcd-1234-uvxyz-9876\n",
    "%env NBY_ENV_NAME=nearbyone.innovationlab\n",
    "%env NBY_ENV_EMAIL=fake.username@example.com\n",
    "%env NBY_ENV_PASSWORD=fake-password\n",
    "# This is to avoid CI pipelines to deploy anything\n",
    "%env LOCAL_DEPLOY=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a9ddc3",
   "metadata": {},
   "source": [
    "## Pre-run cleanup\n",
    "\n",
    "Make sure that the experiment isn't already running by removing its namespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f699b3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Make sure \"scanflow\" path is added in available module paths\n",
    "sys.path.insert(0,'../..')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab94a62",
   "metadata": {},
   "source": [
    "Let's define some useful Kubernetes client functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34845275",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kubernetes import client\n",
    "from kubernetes import config\n",
    "from kubernetes.client.rest import ApiException\n",
    "from kubernetes.stream import stream\n",
    "from scanflow.tools import env\n",
    "import tarfile\n",
    "import os\n",
    "from time import time, sleep\n",
    "import yaml\n",
    "import io\n",
    "import pathlib\n",
    "\n",
    "\n",
    "def delete_namespace_and_wait(client: client.CoreV1Api = None, namespace:str = None, timeout:int = 300):\n",
    "    \"\"\"\n",
    "    Deletes a namespace and waits until its deletion is fully terminated.\n",
    "\n",
    "    Parameters:\n",
    "    - client: client.CoreV1Api - A Kubernetes API client; locally initialized if not provided\n",
    "    - namespace: str - The name of the namespace to delete\n",
    "    - timeout: int - Time to wait in seconds before giving up (default: 300)\n",
    "    \"\"\"\n",
    "    if not client:\n",
    "        client = client.CoreV1Api()\n",
    "    \n",
    "    try:\n",
    "        # Delete the namespace\n",
    "        client.delete_namespace(name=namespace)\n",
    "        # Wait for the namespace to be completely deleted\n",
    "        start_time = time()\n",
    "        while True:\n",
    "            try:\n",
    "                # Try fetching the namespace, if it's still there\n",
    "                response = client.read_namespace(name=namespace)\n",
    "                print(f\"Namespace '{namespace}' is still being deleted...\")\n",
    "            except ApiException as e:\n",
    "                if e.status == 404:\n",
    "                    # Namespace is deleted, exit loop\n",
    "                    print(f\"Namespace '{namespace}' has been successfully deleted.\")\n",
    "                    break\n",
    "                else:\n",
    "                    print(f\"Error occurred: {e}\")\n",
    "                    raise\n",
    "            # Check if timeout is reached\n",
    "            if time() - start_time > timeout:\n",
    "                print(f\"Timeout reached: Namespace '{namespace}' still exists after {timeout} seconds.\")\n",
    "                break\n",
    "\n",
    "            # Wait for some time before checking again\n",
    "            sleep(5)\n",
    "    \n",
    "    except ApiException as e:\n",
    "        print(f\"Failed to delete namespace '{namespace}': {e}\")\n",
    "\n",
    "\n",
    "def deploy_pod_and_wait_for_completion(client: client.CoreV1Api = None, yaml_file: str = None, namespace: str = \"default\", timeout: int = 300) -> None:\n",
    "    \"\"\"\n",
    "    Deploy a pod from a YAML manifest and wait until it reaches the Completed state.\n",
    "\n",
    "    Parameters:\n",
    "    - client: client.CoreV1Api - Kubernetes API client; locally initialized if not provided\n",
    "    - namespace: str - Kubernetes namespace (default: \"default\")\n",
    "    - timeout: int - Time to wait in seconds before giving up (default: 300)\n",
    "    \"\"\"\n",
    "\n",
    "    if not client:\n",
    "        client = client.CoreV1Api()\n",
    "\n",
    "    # Load the YAML file\n",
    "    if not yaml_file:\n",
    "        print(f\"Missing YAML file! Please make sure to provide a valid YAML file path\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    with open(yaml_file, 'r') as f:\n",
    "        pod_manifest = yaml.safe_load(f)\n",
    "\n",
    "    # Extract pod name from the manifest\n",
    "    pod_name = pod_manifest['metadata']['name']\n",
    "\n",
    "    try:\n",
    "        # Create the pod\n",
    "        print(f\"Creating pod: {pod_name} in namespace: {namespace}\")\n",
    "        client.create_namespaced_pod(namespace=namespace, body=pod_manifest)\n",
    "\n",
    "        # Wait for the pod to reach Completed state\n",
    "        start_time = time()\n",
    "        while True:\n",
    "            try:\n",
    "                # Get the pod's current status\n",
    "                pod = client.read_namespaced_pod(name=pod_name, namespace=namespace)\n",
    "                pod_phase = pod.status.phase\n",
    "                print(f\"Pod '{pod_name}' is currently in phase: {pod_phase}\")\n",
    "                \n",
    "                if pod_phase == \"Succeeded\":\n",
    "                    print(f\"Pod '{pod_name}' has completed successfully (Succeeded).\")\n",
    "                    break\n",
    "                elif pod_phase == \"Failed\":\n",
    "                    print(f\"Pod '{pod_name}' has failed.\")\n",
    "                    break\n",
    "                \n",
    "            except ApiException as e:\n",
    "                print(f\"Error fetching pod status: {e}\")\n",
    "                raise\n",
    "\n",
    "            # Check if timeout is reached\n",
    "            if time() - start_time > timeout:\n",
    "                print(f\"Timeout reached: Pod '{pod_name}' is not in Completed state after {timeout} seconds.\")\n",
    "                break\n",
    "\n",
    "            # Wait for a few seconds before checking again\n",
    "            sleep(5)\n",
    "\n",
    "    except ApiException as e:\n",
    "        print(f\"Failed to create pod '{pod_name}': {e}\")\n",
    "\n",
    "\n",
    "def deploy_pod_and_wait(client: client.CoreV1Api = None, yaml_file: str = None, namespace: str = \"default\", timeout: int = 300) -> None:\n",
    "    \"\"\"\n",
    "    Deploys a pod using a YAML manifest and waits until its state is 'Running'.\n",
    "\n",
    "    Parameters:\n",
    "    - client: client.CoreV1Api - Kubernetes API client; locally initialized if not provided\n",
    "    - yaml_file: str - Path to the YAML file containing the pod manifest.\n",
    "    - namespace: str - Kubernetes namespace (default: 'default').\n",
    "    - timeout: int - Time to wait in seconds before timing out (default: 300).\n",
    "    \"\"\"\n",
    "\n",
    "    # Load YAML file\n",
    "    with open(yaml_file, 'r') as f:\n",
    "        pod_manifest = yaml.safe_load(f)\n",
    "\n",
    "    # Extract pod name from manifest\n",
    "    pod_name = pod_manifest['metadata']['name']\n",
    "    \n",
    "    try:\n",
    "        # Create the pod\n",
    "        print(f\"Creating pod: {pod_name} in namespace: {namespace}\")\n",
    "        client.create_namespaced_pod(namespace=namespace, body=pod_manifest)\n",
    "\n",
    "        # Wait for the pod to reach Running state\n",
    "        start_time = time()\n",
    "        while True:\n",
    "            try:\n",
    "                # Get the pod's current status\n",
    "                pod = client.read_namespaced_pod(name=pod_name, namespace=namespace)\n",
    "                pod_phase = pod.status.phase\n",
    "                print(f\"Pod '{pod_name}' is currently in phase: {pod_phase}\")\n",
    "                \n",
    "                if pod_phase == \"Running\":\n",
    "                    print(f\"Pod '{pod_name}' is now in Running state.\")\n",
    "                    break\n",
    "                elif pod_phase == \"Failed\":\n",
    "                    print(f\"Pod '{pod_name}' has failed to start.\")\n",
    "                    break\n",
    "                \n",
    "            except ApiException as e:\n",
    "                print(f\"Error fetching pod status: {e}\")\n",
    "                raise\n",
    "\n",
    "            # Check if timeout is reached\n",
    "            if time() - start_time > timeout:\n",
    "                print(f\"Timeout reached: Pod '{pod_name}' is not in Running state after {timeout} seconds.\")\n",
    "                break\n",
    "\n",
    "            # Wait for a few seconds before checking again\n",
    "            sleep(5)\n",
    "\n",
    "    except ApiException as e:\n",
    "        print(f\"Failed to create pod '{pod_name}': {e}\")\n",
    "\n",
    "\n",
    "def check_if_object_exists_and_ready(\n",
    "    client: client.CoreV1Api = None, # Kubernetes API client; locally initialized if not provided\n",
    "    object_type: str = \"namespace\",  # Type of Kubernetes object: 'namespace' or 'persistentVolumeClaim'\n",
    "    name: str = \"default\",  # Name of the Kubernetes object (namespace or PVC)\n",
    "    namespace: str = None  # Namespace where the object is located (only for PVC)\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Checks if a Kubernetes object (namespace or persistentVolumeClaim) exists and is ready.\n",
    "\n",
    "    Parameters:\n",
    "    - object_type: str - Type of Kubernetes object ('namespace' or 'persistentVolumeClaim').\n",
    "    - name: str - Name of the Kubernetes object.\n",
    "    - namespace: str - Namespace where the object is located (only relevant for PVCs).\n",
    "\n",
    "    Returns:\n",
    "    - bool: True if the object exists and is ready, False otherwise.\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    # Initialize API clients\n",
    "    if not client:\n",
    "        client = client.CoreV1Api()\n",
    "\n",
    "    try:\n",
    "        if object_type == \"namespace\":\n",
    "            # Check if the namespace exists\n",
    "            print(f\"Checking if namespace '{name}' exists...\")\n",
    "            namespace_obj = client.read_namespace(name=name)\n",
    "            if namespace_obj.status.phase == \"Active\":\n",
    "                print(f\"Namespace '{name}' exists and is Active.\")\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"Namespace '{name}' is not Active.\")\n",
    "                return False\n",
    "\n",
    "        elif object_type == \"persistentVolumeClaim\":\n",
    "            if namespace is None:\n",
    "                raise ValueError(\"Namespace must be specified for persistentVolumeClaim check.\")\n",
    "\n",
    "            # Check if the PVC exists and is bound\n",
    "            print(f\"Checking if persistentVolumeClaim '{name}' exists in namespace '{namespace}'...\")\n",
    "            pvc_obj = client.read_namespaced_persistent_volume_claim(name=name, namespace=namespace)\n",
    "            if pvc_obj.status.phase == \"Bound\":\n",
    "                print(f\"PersistentVolumeClaim '{name}' is Bound and ready.\")\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"PersistentVolumeClaim '{name}' is not in Bound state.\")\n",
    "                return False\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported object type '{object_type}'. Use 'namespace' or 'persistentVolumeClaim'.\")\n",
    "\n",
    "    except ApiException as e:\n",
    "        if e.status == 404:\n",
    "            print(f\"{object_type.capitalize()} '{name}' not found.\")\n",
    "        else:\n",
    "            print(f\"Error fetching {object_type} status: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "def copy_local_path_to_pod(client: client.CoreV1Api, namespace: str, pod_name: str, local_path: pathlib.Path, dest_path: str, exclude_paths: list = []):\n",
    "    \"\"\"\n",
    "    Transfer the content of a local path to the desired pod\n",
    "    \"\"\"\n",
    "    import re, os\n",
    "\n",
    "    # Define the pattern to exclude undesired paths to transfer\n",
    "    pattern = '.*(?:% s)' % '|'.join(exclude_paths)\n",
    "\n",
    "    buf = io.BytesIO()\n",
    "    with tarfile.open(fileobj=buf, mode='w:tar') as tar:\n",
    "        tar.add(\n",
    "            local_path,\n",
    "            arcname=pathlib.Path(dest_path).joinpath(local_path.name),\n",
    "            filter=lambda x: None if re.match(pattern, x.name) else x\n",
    "        )\n",
    "    \n",
    "    commands = [buf.getvalue()]\n",
    "\n",
    "    # Copying file\n",
    "    exec_command = ['tar', 'xvf', '-', '-C', '/']\n",
    "    resp = stream(client.connect_get_namespaced_pod_exec, pod_name, namespace,\n",
    "                         command=exec_command,\n",
    "                         stderr=True, stdin=True,\n",
    "                         stdout=True, tty=False,\n",
    "                         _preload_content=False)\n",
    "\n",
    "    while resp.is_open():\n",
    "        resp.update(timeout=1)\n",
    "        if resp.peek_stdout():\n",
    "            print(f\"STDOUT: {resp.read_stdout()}\")\n",
    "        if resp.peek_stderr():\n",
    "            print(f\"STDERR: {resp.read_stderr()}\")\n",
    "        if commands:\n",
    "            c = commands.pop(0)\n",
    "            resp.write_stdin(c)\n",
    "        else:\n",
    "            break\n",
    "    resp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72129c97",
   "metadata": {},
   "source": [
    "Remove the experiment namespace if it exists in the Kubernetes cluster:\n",
    "- Wait for its proper termination before proceeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a45e7a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jolivera/.kube/config_ncloud_socat\n"
     ]
    },
    {
     "ename": "MaxRetryError",
     "evalue": "HTTPSConnectionPool(host='84.88.189.179', port=8001): Max retries exceeded with url: /api/v1/namespaces (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7a0ce4499c50>, 'Connection to 84.88.189.179 timed out. (connect timeout=None)'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/dataconnector/lib/python3.11/site-packages/urllib3/connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout:\n",
      "File \u001b[0;32m~/miniconda3/envs/dataconnector/lib/python3.11/site-packages/urllib3/util/connection.py:95\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m socket\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgetaddrinfo returns an empty list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/dataconnector/lib/python3.11/site-packages/urllib3/util/connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     84\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 85\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sock\n",
      "\u001b[0;31mTimeoutError\u001b[0m: [Errno 110] Connection timed out",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectTimeoutError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/dataconnector/lib/python3.11/site-packages/urllib3/connectionpool.py:716\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 716\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    729\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dataconnector/lib/python3.11/site-packages/urllib3/connectionpool.py:404\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 404\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;66;03m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dataconnector/lib/python3.11/site-packages/urllib3/connectionpool.py:1061\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msock\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[0;32m-> 1061\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified:\n",
      "File \u001b[0;32m~/miniconda3/envs/dataconnector/lib/python3.11/site-packages/urllib3/connection.py:363\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;66;03m# Add certificate verification\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m     hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n",
      "File \u001b[0;32m~/miniconda3/envs/dataconnector/lib/python3.11/site-packages/urllib3/connection.py:179\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout:\n\u001b[0;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ConnectTimeoutError(\n\u001b[1;32m    180\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    181\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection to \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m timed out. (connect timeout=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    182\u001b[0m         \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout),\n\u001b[1;32m    183\u001b[0m     )\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mConnectTimeoutError\u001b[0m: (<urllib3.connection.HTTPSConnection object at 0x7a0ce4499c50>, 'Connection to 84.88.189.179 timed out. (connect timeout=None)')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m kube_client \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mCoreV1Api()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Look for all available namespaces\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m namespaces \u001b[38;5;241m=\u001b[39m \u001b[43mkube_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_namespace\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Compose the expected namespace that Scanflow creates based on app_name and team_name\u001b[39;00m\n\u001b[1;32m     14\u001b[0m environment_namespace \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscanflow-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00menv\u001b[38;5;241m.\u001b[39mget_env(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSCANFLOW_APP_NAME\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00menv\u001b[38;5;241m.\u001b[39mget_env(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSCANFLOW_TEAM_NAME\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/dataconnector/lib/python3.11/site-packages/kubernetes/client/api/core_v1_api.py:14817\u001b[0m, in \u001b[0;36mCoreV1Api.list_namespace\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m  14785\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"list_namespace  # noqa: E501\u001b[39;00m\n\u001b[1;32m  14786\u001b[0m \n\u001b[1;32m  14787\u001b[0m \u001b[38;5;124;03mlist or watch objects of kind Namespace  # noqa: E501\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  14814\u001b[0m \u001b[38;5;124;03m         returns the request thread.\u001b[39;00m\n\u001b[1;32m  14815\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m  14816\u001b[0m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_return_http_data_only\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m> 14817\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_namespace_with_http_info\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dataconnector/lib/python3.11/site-packages/kubernetes/client/api/core_v1_api.py:14928\u001b[0m, in \u001b[0;36mCoreV1Api.list_namespace_with_http_info\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m  14925\u001b[0m \u001b[38;5;66;03m# Authentication setting\u001b[39;00m\n\u001b[1;32m  14926\u001b[0m auth_settings \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBearerToken\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[0;32m> 14928\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapi_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_api\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  14929\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/api/v1/namespaces\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m  14930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  14931\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  14932\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheader_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  14933\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  14934\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mform_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  14935\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_var_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  14936\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mV1NamespaceList\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# noqa: E501\u001b[39;49;00m\n\u001b[1;32m  14937\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  14938\u001b[0m \u001b[43m    \u001b[49m\u001b[43masync_req\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_var_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43masync_req\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  14939\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_return_http_data_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_var_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_return_http_data_only\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# noqa: E501\u001b[39;49;00m\n\u001b[1;32m  14940\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_var_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_preload_content\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  14941\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_var_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_request_timeout\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m  14942\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcollection_formats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollection_formats\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dataconnector/lib/python3.11/site-packages/kubernetes/client/api_client.py:348\u001b[0m, in \u001b[0;36mApiClient.call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, async_req, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Makes the HTTP request (synchronous) and returns deserialized data.\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \n\u001b[1;32m    313\u001b[0m \u001b[38;5;124;03mTo make an async_req request, set the async_req parameter.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;124;03m    then the method will return the response directly.\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m async_req:\n\u001b[0;32m--> 348\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__call_api\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresource_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mpath_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mresponse_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m                           \u001b[49m\u001b[43m_return_http_data_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollection_formats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m                           \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_host\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39mapply_async(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__call_api, (resource_path,\n\u001b[1;32m    356\u001b[0m                                                method, path_params,\n\u001b[1;32m    357\u001b[0m                                                query_params,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    365\u001b[0m                                                _request_timeout,\n\u001b[1;32m    366\u001b[0m                                                _host))\n",
      "File \u001b[0;32m~/miniconda3/envs/dataconnector/lib/python3.11/site-packages/kubernetes/client/api_client.py:180\u001b[0m, in \u001b[0;36mApiClient.__call_api\u001b[0;34m(self, resource_path, method, path_params, query_params, header_params, body, post_params, files, response_type, auth_settings, _return_http_data_only, collection_formats, _preload_content, _request_timeout, _host)\u001b[0m\n\u001b[1;32m    177\u001b[0m     url \u001b[38;5;241m=\u001b[39m _host \u001b[38;5;241m+\u001b[39m resource_path\n\u001b[1;32m    179\u001b[0m \u001b[38;5;66;03m# perform request and return response\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m response_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheader_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpost_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpost_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_request_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_response \u001b[38;5;241m=\u001b[39m response_data\n\u001b[1;32m    188\u001b[0m return_data \u001b[38;5;241m=\u001b[39m response_data\n",
      "File \u001b[0;32m~/miniconda3/envs/dataconnector/lib/python3.11/site-packages/kubernetes/client/api_client.py:373\u001b[0m, in \u001b[0;36mApiClient.request\u001b[0;34m(self, method, url, query_params, headers, post_params, body, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Makes the HTTP request using RESTClient.\"\"\"\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGET\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 373\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrest_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGET\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m                                \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m                                \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHEAD\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrest_client\u001b[38;5;241m.\u001b[39mHEAD(url,\n\u001b[1;32m    380\u001b[0m                                  query_params\u001b[38;5;241m=\u001b[39mquery_params,\n\u001b[1;32m    381\u001b[0m                                  _preload_content\u001b[38;5;241m=\u001b[39m_preload_content,\n\u001b[1;32m    382\u001b[0m                                  _request_timeout\u001b[38;5;241m=\u001b[39m_request_timeout,\n\u001b[1;32m    383\u001b[0m                                  headers\u001b[38;5;241m=\u001b[39mheaders)\n",
      "File \u001b[0;32m~/miniconda3/envs/dataconnector/lib/python3.11/site-packages/kubernetes/client/rest.py:244\u001b[0m, in \u001b[0;36mRESTClientObject.GET\u001b[0;34m(self, url, headers, query_params, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mGET\u001b[39m(\u001b[38;5;28mself\u001b[39m, url, headers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, query_params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, _preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    243\u001b[0m         _request_timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 244\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m                        \u001b[49m\u001b[43m_preload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m                        \u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mquery_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dataconnector/lib/python3.11/site-packages/kubernetes/client/rest.py:217\u001b[0m, in \u001b[0;36mRESTClientObject.request\u001b[0;34m(self, method, url, query_params, headers, body, post_params, _preload_content, _request_timeout)\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m ApiException(status\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, reason\u001b[38;5;241m=\u001b[39mmsg)\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# For `GET`, `HEAD`\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 217\u001b[0m         r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpool_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_preload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m urllib3\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mSSLError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    223\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(e)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;28mstr\u001b[39m(e))\n",
      "File \u001b[0;32m~/miniconda3/envs/dataconnector/lib/python3.11/site-packages/urllib3/request.py:77\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[0;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[1;32m     74\u001b[0m urlopen_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest_url\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m url\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_encode_url_methods:\n\u001b[0;32m---> 77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_encode_url\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43murlopen_kw\u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_body(\n\u001b[1;32m     82\u001b[0m         method, url, fields\u001b[38;5;241m=\u001b[39mfields, headers\u001b[38;5;241m=\u001b[39mheaders, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw\n\u001b[1;32m     83\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/dataconnector/lib/python3.11/site-packages/urllib3/request.py:99\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_url\u001b[0;34m(self, method, url, fields, headers, **urlopen_kw)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fields:\n\u001b[1;32m     97\u001b[0m     url \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m urlencode(fields)\n\u001b[0;32m---> 99\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dataconnector/lib/python3.11/site-packages/urllib3/poolmanager.py:376\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[0;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[1;32m    374\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 376\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[0;32m~/miniconda3/envs/dataconnector/lib/python3.11/site-packages/urllib3/connectionpool.py:830\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    825\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[1;32m    826\u001b[0m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[1;32m    827\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    828\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[1;32m    829\u001b[0m     )\n\u001b[0;32m--> 830\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[1;32m    847\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n",
      "File \u001b[0;32m~/miniconda3/envs/dataconnector/lib/python3.11/site-packages/urllib3/connectionpool.py:830\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    825\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[1;32m    826\u001b[0m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[1;32m    827\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    828\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[1;32m    829\u001b[0m     )\n\u001b[0;32m--> 830\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[1;32m    847\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n",
      "File \u001b[0;32m~/miniconda3/envs/dataconnector/lib/python3.11/site-packages/urllib3/connectionpool.py:830\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    825\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[1;32m    826\u001b[0m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[1;32m    827\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m    828\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[1;32m    829\u001b[0m     )\n\u001b[0;32m--> 830\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    841\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[1;32m    847\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n",
      "File \u001b[0;32m~/miniconda3/envs/dataconnector/lib/python3.11/site-packages/urllib3/connectionpool.py:802\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, (SocketError, HTTPException)):\n\u001b[1;32m    800\u001b[0m     e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[0;32m--> 802\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    805\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n\u001b[1;32m    807\u001b[0m \u001b[38;5;66;03m# Keep track of the error for the retry warning.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dataconnector/lib/python3.11/site-packages/urllib3/util/retry.py:594\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    583\u001b[0m new_retry \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnew(\n\u001b[1;32m    584\u001b[0m     total\u001b[38;5;241m=\u001b[39mtotal,\n\u001b[1;32m    585\u001b[0m     connect\u001b[38;5;241m=\u001b[39mconnect,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    590\u001b[0m     history\u001b[38;5;241m=\u001b[39mhistory,\n\u001b[1;32m    591\u001b[0m )\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_retry\u001b[38;5;241m.\u001b[39mis_exhausted():\n\u001b[0;32m--> 594\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause))\n\u001b[1;32m    596\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n\u001b[1;32m    598\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_retry\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='84.88.189.179', port=8001): Max retries exceeded with url: /api/v1/namespaces (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x7a0ce4499c50>, 'Connection to 84.88.189.179 timed out. (connect timeout=None)'))"
     ]
    }
   ],
   "source": [
    "# Initialize kube config and client\n",
    "# DEBUG: show the kubeconfig path due to GitHub CI issues\n",
    "print(env.get_env(\"KUBECONFIG_PATH\"))\n",
    "try:\n",
    "    config.load_kube_config(config_file=env.get_env(\"KUBECONFIG_PATH\"))\n",
    "except Exception as e:\n",
    "    raise Exception(f\"Something wrong with kubeconfig at {env.get_env('KUBECONFIG_PATH'): {e}}\")\n",
    "\n",
    "kube_client = client.CoreV1Api()\n",
    "\n",
    "# Look for all available namespaces\n",
    "namespaces = kube_client.list_namespace()\n",
    "# Compose the expected namespace that Scanflow creates based on app_name and team_name\n",
    "environment_namespace = f\"scanflow-{env.get_env('SCANFLOW_APP_NAME')}-{env.get_env('SCANFLOW_TEAM_NAME')}\"\n",
    "\n",
    "# Remove the namespace if it exists\n",
    "for namespace in namespaces.items:\n",
    "    if environment_namespace == namespace.metadata.name:\n",
    "        delete_namespace_and_wait(client=kube_client, namespace=environment_namespace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62dd58c",
   "metadata": {},
   "source": [
    "Remove any experiment's pre-built docker image as they prevent fresh builds if the `repository:tag` is found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53c440c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import docker\n",
    "docker_client=docker.DockerClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d89f3a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purging containers...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purging docker tags starting with registry.gitlab.bsc.es/datacentric-computing/cloudskin-project/cloudskin-registry/cloudedge-proactive-migration-experiment-datascience...\n"
     ]
    }
   ],
   "source": [
    "# Also remove any pre-built docker image\n",
    "import docker\n",
    "\n",
    "repository_prefix = f\"{env.get_env('DOCKER_REGISTRY')}/{env.get_env('SCANFLOW_APP_NAME')}-{env.get_env('SCANFLOW_TEAM_NAME')}\"\n",
    "\n",
    "docker_client = docker.DockerClient()\n",
    "\n",
    "# - First remove any unused container\n",
    "print(\"Purging containers...\")\n",
    "docker_client.containers.prune()\n",
    "\n",
    "# - Then prune any image that matches the repository_prefix\n",
    "print(f\"Purging docker tags starting with {repository_prefix}...\")\n",
    "for docker_image in docker_client.images.list():\n",
    "    for tag in docker_image.tags:\n",
    "        if tag.startswith(repository_prefix):\n",
    "            docker_client.images.remove(tag)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5bca15",
   "metadata": {},
   "source": [
    "## ScanflowClient initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b49e1b0-c77a-43cb-82ee-0e9aa58b3c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanflow\n",
    "from scanflow.client import ScanflowClient\n",
    "# from scanflow.client import ScanflowTrackerClient\n",
    "from scanflow.client import ScanflowDeployerClient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b175b7",
   "metadata": {},
   "source": [
    "### Debug: available environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d468eb3f-3008-4993-b72c-b6964eb1bca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://84.88.189.179:32767\n",
      "http://84.88.189.179:32766\n",
      "http://84.88.189.179:32645\n",
      "scanflow\n",
      "scanflow123\n",
      "registry.gitlab.bsc.es/datacentric-computing/cloudskin-project/cloudskin-registry\n",
      "feat/proactive-migration\n"
     ]
    }
   ],
   "source": [
    "print(env.get_env(\"SCANFLOW_SERVER_URI\"))\n",
    "print(env.get_env(\"SCANFLOW_TRACKER_URI\"))\n",
    "#print(env.get_env(\"SCANFLOW_TRACKER_LOCAL_URI\"))\n",
    "print(env.get_env(\"MLFLOW_S3_ENDPOINT_URL\"))\n",
    "print(env.get_env(\"AWS_ACCESS_KEY_ID\"))\n",
    "print(env.get_env(\"AWS_SECRET_ACCESS_KEY\"))\n",
    "print(env.get_env(\"DOCKER_REGISTRY\"))\n",
    "print(env.get_env(\"DOCKER_TAG\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9645c47",
   "metadata": {},
   "source": [
    "Initialize the ScanflowClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7965691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jolivera/Documents/CloudSkin/Scanflow/data-connector/examples/cloudedge-proactive-migration/datascience\n"
     ]
    }
   ],
   "source": [
    "# App folder - Must point to the folder includeing all 'dataengineer' and 'datascience' folders\n",
    "# for cloudedge-reactive-migration, allocated in examples/cloudedge-reactive-migration\n",
    "app_dir = os.path.join(env.get_env('WORKDIR'), env.get_env('PROACTIVE_MIGRATION_DATASCIENCE_APP_DIR'))\n",
    "print(app_dir)\n",
    "app_name = env.get_env(\"SCANFLOW_APP_NAME\")\n",
    "team_name = env.get_env(\"SCANFLOW_TEAM_NAME\")\n",
    "\n",
    "# Initialize the Scanflow Client\n",
    "scanflow_client = ScanflowClient(\n",
    "    #if you defined \"SCANFLOW_SERVER_URI\", you dont need to provide this\n",
    "    registry=env.get_env(\"DOCKER_REGISTRY\"),\n",
    "    verbose=True,\n",
    "    docker_network_mode=\"host\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcf64b4",
   "metadata": {},
   "source": [
    "## Data Science graph for proactive training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d502a46",
   "metadata": {},
   "source": [
    "### Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e55a550-91bd-4172-adc4-a8c93dfd246c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # App folder\n",
    "# scanflow_path = \"/home/rocky/k8s_resources/data-connector\"\n",
    "# app_dir = os.path.join(scanflow_path, \"examples/cloudedge/datascience\")\n",
    "# app_name = \"cloudedge\"\n",
    "# team_name = \"datascience\"\n",
    "\n",
    "# # scanflow client\n",
    "# client = ScanflowClient(\n",
    "#              #if you defined \"SCANFLOW_SERVER_URI\", you dont need to provide this\n",
    "#              #scanflow_server_uri=\"http://172.30.0.50:46666\",\n",
    "#              verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380b73df-8f8f-4319-88b0-50356b1c27d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DUMY: now the modelling simply save a resnet model\n",
    "\n",
    "# executor1 = client.ScanflowExecutor(name='load-data', \n",
    "#                       mainfile='main.py',\n",
    "#                       parameters={\n",
    "#                         '--config': '/home/rocky/k8s_resources/data-connector/examples/cloudedge/datascience/workflows/load-data/config_prep.json',\n",
    "#                                   },\n",
    "#                       requirements='requirements.txt',\n",
    "#                       dockerfile='dockerfile')\n",
    "\n",
    "# Predictor stages\n",
    "# - Executor 1: Data retrieval from Prometheus\n",
    "# - Executor 2: Data pre-processing + QoS Predictor\n",
    "\n",
    "# Define common variables for the Application stages\n",
    "output_dir = \"/workflow\"\n",
    "csv_root_path = os.path.join(output_dir, f\"{app_name}-{team_name}\")\n",
    "\n",
    "executor3 = scanflow_client.ScanflowExecutor(name='modeling', \n",
    "                      mainfile='mlflow_loader.py',\n",
    "                      dockerfile='Dockerfile_mod_no_buildkit',\n",
    "                      image_pull_policy=\"IfNotPresent\",\n",
    "                      parameters=None\n",
    "                      )\n",
    "\n",
    "# dependency1 = client.ScanflowDependency(dependee='preprocessing',\n",
    "#                                     depender='modeling')\n",
    "\n",
    "\n",
    "##workflow1 \n",
    "workflow1 = scanflow_client.ScanflowWorkflow(name='proactive-training-datascience', \n",
    "                     nodes=[executor3],\n",
    "                    #  edges=[dependency1],\n",
    "                    type = \"batch\",\n",
    "                    output_dir = output_dir,\n",
    "                    cron=\"*/5 * * * *\",\n",
    "                    image_pull_secrets=[\"cloudskin-registry\"] # Required for Workflow templates\n",
    ")\n",
    "\n",
    "              "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982a8172",
   "metadata": {},
   "source": [
    "### Compose the Scanflow Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e448dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = scanflow_client.ScanflowApplication(app_name = app_name,\n",
    "                                 app_dir = app_dir,\n",
    "                                 team_name = team_name,\n",
    "                                 workflows=[workflow1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382472a8",
   "metadata": {},
   "source": [
    "### DEBUG: show application config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f703914",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26-Nov-24 11:24:40 -  INFO - workflow proactive-training-datascience: {'name': 'proactive-training-datascience', 'nodes': [{'name': 'modeling', 'node_type': 'executor', 'mainfile': 'mlflow_loader.py', 'parameters': None, 'requirements': None, 'dockerfile': 'Dockerfile_mod_no_buildkit', 'base_image': None, 'env': None, 'image': None, 'timeout': None, 'resources': None, 'affinity': None, 'image_pull_policy': 'IfNotPresent'}], 'edges': None, 'type': 'batch', 'cron': '*/5 * * * *', 'resources': None, 'affinity': None, 'kedaSpec': None, 'hpaSpec': None, 'output_dir': '/workflow', 'image_pull_secrets': ['cloudskin-registry']}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'app_name': 'cloudedge-proactive-migration-experiment',\n",
       " 'app_dir': '/home/jolivera/Documents/CloudSkin/Scanflow/data-connector/examples/cloudedge-proactive-migration/datascience',\n",
       " 'team_name': 'datascience',\n",
       " 'workflows': [{'name': 'proactive-training-datascience',\n",
       "   'nodes': [{'name': 'modeling',\n",
       "     'node_type': 'executor',\n",
       "     'mainfile': 'mlflow_loader.py',\n",
       "     'parameters': None,\n",
       "     'requirements': None,\n",
       "     'dockerfile': 'Dockerfile_mod_no_buildkit',\n",
       "     'base_image': None,\n",
       "     'env': None,\n",
       "     'image': None,\n",
       "     'timeout': None,\n",
       "     'resources': None,\n",
       "     'affinity': None,\n",
       "     'image_pull_policy': 'IfNotPresent'}],\n",
       "   'edges': None,\n",
       "   'type': 'batch',\n",
       "   'cron': '*/5 * * * *',\n",
       "   'resources': None,\n",
       "   'affinity': None,\n",
       "   'kedaSpec': None,\n",
       "   'hpaSpec': None,\n",
       "   'output_dir': '/workflow',\n",
       "   'image_pull_secrets': ['cloudskin-registry']}],\n",
       " 'agents': None,\n",
       " 'tracker': None}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5371c4bb",
   "metadata": {},
   "source": [
    "### Build the Scanflow Application\n",
    "- This step builds the Docker images for all the Scanflow executors and uploads them to the container registry (currently hardcoded in the `scanflow` module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0011420",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26-Nov-24 11:24:40 -  INFO - Building image registry.gitlab.bsc.es/datacentric-computing/cloudskin-project/cloudskin-registry/cloudedge-proactive-migration-experiment-datascience-proactive-training-datascience-modeling\n",
      "26-Nov-24 11:24:40 -  INFO - [+] Image [registry.gitlab.bsc.es/datacentric-computing/cloudskin-project/cloudskin-registry/cloudedge-proactive-migration-experiment-datascience-proactive-training-datascience-modeling] not found in repository. Building a new one.\n",
      "26-Nov-24 11:24:40 -  INFO - dockerfile for using /home/jolivera/Documents/CloudSkin/Scanflow/data-connector/examples/cloudedge-proactive-migration/datascience/workflows/modeling/Dockerfile_mod_no_buildkit from /home/jolivera/Documents/CloudSkin/Scanflow/data-connector/examples/cloudedge-proactive-migration/datascience/workflows\n",
      "26-Nov-24 11:29:35 -  INFO - [+] Image [modeling] was built successfully. image_tag ['registry.gitlab.bsc.es/datacentric-computing/cloudskin-project/cloudskin-registry/cloudedge-proactive-migration-experiment-datascience-proactive-training-datascience-modeling:feat-proactive-migration']\n",
      "26-Nov-24 11:35:56 -  INFO - [+] Image [modeling] was pushed to registry successfully.\n"
     ]
    }
   ],
   "source": [
    "# Define the Scanflow Tracker Port (32767)\n",
    "build_app = scanflow_client.build_ScanflowApplication(\n",
    "    app=app,\n",
    "    trackerPort=32760, # Change this port to avoid conflict with any svc already using it.\n",
    "    image_pull_secret=\"cloudskin-registry\" # Required when deploying to Kubernetes (created during deployment)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7309326c",
   "metadata": {},
   "source": [
    "### DEBUG: show built application config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971ef799",
   "metadata": {},
   "outputs": [],
   "source": [
    "#build_app.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627143eb",
   "metadata": {},
   "source": [
    "### Create a ScanflowDeployerClient\n",
    "\n",
    "This client creates the required environment for Scanflow to run the pipelines in a Kubernetes cluster based on the built application. It can:\n",
    "\n",
    "- Create an environment for the Scanflow application within its own namespace\n",
    "- Deploy a local Scanflow Tracker\n",
    "- Run the application as an Argo Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88febc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26-Nov-24 11:35:56 -  INFO - loading kubernetes configuration from /home/jolivera/.kube/config_ncloud_socat\n",
      "26-Nov-24 11:35:56 -  INFO - found local kubernetes configuration\n"
     ]
    }
   ],
   "source": [
    "# Initialize the deployer client\n",
    "if env.get_env(\"LOCAL_DEPLOY\"):\n",
    "    deployer_client = ScanflowDeployerClient(\n",
    "        user_type=\"local\",\n",
    "        deployer=\"argo\",\n",
    "        k8s_config_file=env.get_env(\"KUBECONFIG_PATH\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5971df8",
   "metadata": {},
   "source": [
    "### Deploy the ScanflowEnvironment\n",
    "This creates:\n",
    "- A namespace for the application\n",
    "- A Deployment for the local scanflow tracker\n",
    "- A Deployment for all the agents (in this case there's only the planner)\n",
    "  - Planner doesn't include right now the `scanflow` module, so it must be copied inside the planner's PVC so the container finds it in the `/scanflow/scanflow/scanflow` path\n",
    "\n",
    "Go to your Kubernetes cluster and check that both tracker and planner pods are Running without errors in the `scanflow-cloudedge-reactive-migration-dataengineer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0c5738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compose a custom ScanflowEnvironment\n",
    "from scanflow.deployer.env import ScanflowEnvironment\n",
    "data_sci_env = ScanflowEnvironment()\n",
    "data_sci_env.namespace=f\"scanflow-{build_app.app_name}-{build_app.team_name}\"\n",
    "# TRACKER STORAGE MUST BE ALREADY DEPLOYED IN ITS OWN NAMESPACE (i.e: \"scanflow-server\")\n",
    "# - \"scanflow\" db must already exist in postgresql\n",
    "# - \"scanflow\" bucket must already exist in MinIO\n",
    "#data_sci_env.tracker_config.TRACKER_STORAGE = f\"postgresql://postgres:scanflow123@postgresql.scanflow-server/scanflow\"\n",
    "data_sci_env.tracker_config.TRACKER_STORAGE = env.get_env(\"SCANFLOW_TRACKER_STORAGE\")\n",
    "data_sci_env.tracker_config.TRACKER_ARTIFACT = f\"s3://scanflow/{data_sci_env.namespace}\"\n",
    "# CLIENT CONFIG: REPLACE WITH CURRENTLY DEPLOYED SERVICES IN \"scanflow-server\" namespace\n",
    "data_sci_env.client_config.SCANFLOW_TRACKER_LOCAL_URI = env.get_env(\"SCANFLOW_SERVER_URI\")\n",
    "data_sci_env.client_config.SCANFLOW_TRACKER_URI = env.get_env(\"SCANFLOW_SERVER_URI\")\n",
    "data_sci_env.client_config.SCANFLOW_SERVER_URI = env.get_env(\"SCANFLOW_SERVER_URI\")\n",
    "# MINIO MUST BE ALREADY DEPLOYED IN ITS OWN NAMESPACE (i.e: \"scanflow-server\")\n",
    "data_sci_env.secret.AWS_ACCESS_KEY_ID = env.get_env(\"AWS_ACCESS_KEY_ID\")\n",
    "data_sci_env.secret.AWS_SECRET_ACCESS_KEY = env.get_env(\"AWS_SECRET_ACCESS_KEY\")\n",
    "data_sci_env.secret.MLFLOW_S3_ENDPOINT_URL = env.get_env(\"MLFLOW_S3_ENDPOINT_URL\")\n",
    "data_sci_env.secret.AWS_ENDPOINT_URL = env.get_env(\"AWS_ENDPOINT_URL\")\n",
    "# NEW: configure image pull secret\n",
    "data_sci_env.image_pull_secret.name = \"cloudskin-registry\"\n",
    "data_sci_env.image_pull_secret.registry = env.get_env(\"DOCKER_REGISTRY\")\n",
    "data_sci_env.image_pull_secret.username = env.get_env(\"DOCKER_REGISTRY_USERNAME\")\n",
    "data_sci_env.image_pull_secret.password = env.get_env(\"DOCKER_REGISTRY_PASSWORD\")\n",
    "data_sci_env.image_pull_secret.email = \"cloudskin-project@bsc.es\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba9bb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26-Nov-24 11:35:56 -  INFO - [++]Creating env\n",
      "26-Nov-24 11:35:56 -  INFO - [++]Creating namespace \"scanflow-cloudedge-proactive-migration-experiment-datascience\"\n",
      "/home/jolivera/miniconda3/envs/dataconnector/lib/python3.11/site-packages/urllib3/connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host '84.88.189.179'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "26-Nov-24 11:35:56 -  INFO - create_namespace true\n",
      "26-Nov-24 11:35:56 -  INFO - [++]Creating Role for 'default service account'\n",
      "/home/jolivera/miniconda3/envs/dataconnector/lib/python3.11/site-packages/urllib3/connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host '84.88.189.179'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "26-Nov-24 11:35:56 -  INFO - create_rolebinding info\n",
      "26-Nov-24 11:35:56 -  INFO - [++]Creating s3 secret {'AWS_ACCESS_KEY_ID': 'scanflow', 'AWS_SECRET_ACCESS_KEY': 'scanflow123', 'MLFLOW_S3_ENDPOINT_URL': 'http://84.88.189.179:32645', 'AWS_ENDPOINT_URL': None}\n",
      "/home/jolivera/miniconda3/envs/dataconnector/lib/python3.11/site-packages/urllib3/connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host '84.88.189.179'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "26-Nov-24 11:35:57 -  INFO - create_secret true\n",
      "26-Nov-24 11:35:57 -  INFO - [++]Creating tracker configmap {'TRACKER_STORAGE': 'postgresql://postgres:scanflow123@scanflow-postgres.scanflow-server.svc.cluster.local/scanflow-cloudedge-datascience', 'TRACKER_ARTIFACT': 's3://scanflow/scanflow-cloudedge-proactive-migration-experiment-datascience'}\n",
      "/home/jolivera/miniconda3/envs/dataconnector/lib/python3.11/site-packages/urllib3/connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host '84.88.189.179'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "26-Nov-24 11:35:57 -  INFO - create_configmap true\n",
      "26-Nov-24 11:35:57 -  INFO - [++]Creating client configmap {'SCANFLOW_TRACKER_URI': 'http://84.88.189.179:32767', 'SCANFLOW_SERVER_URI': 'http://84.88.189.179:32767', 'SCANFLOW_TRACKER_LOCAL_URI': 'http://84.88.189.179:32767'}\n",
      "/home/jolivera/miniconda3/envs/dataconnector/lib/python3.11/site-packages/urllib3/connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host '84.88.189.179'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "26-Nov-24 11:35:57 -  INFO - create_configmap true\n",
      "/home/jolivera/miniconda3/envs/dataconnector/lib/python3.11/site-packages/urllib3/connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host '84.88.189.179'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "26-Nov-24 11:35:57 -  INFO - create_pvc true\n",
      "26-Nov-24 11:35:57 -  INFO - [++]Creating Image Pull Secret for registry.gitlab.bsc.es/datacentric-computing/cloudskin-project/cloudskin-registry\n",
      "/home/jolivera/miniconda3/envs/dataconnector/lib/python3.11/site-packages/urllib3/connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host '84.88.189.179'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "26-Nov-24 11:35:57 -  INFO - create_secret true\n",
      "26-Nov-24 11:35:57 -  INFO - [+] Starting local tracker: [scanflow-tracker].\n",
      "/home/jolivera/miniconda3/envs/dataconnector/lib/python3.11/site-packages/urllib3/connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host '84.88.189.179'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "26-Nov-24 11:35:57 -  INFO - create_deployment true \n",
      "26-Nov-24 11:35:57 -  INFO - [+] Created tracker Deployment True\n",
      "/home/jolivera/miniconda3/envs/dataconnector/lib/python3.11/site-packages/urllib3/connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host '84.88.189.179'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "26-Nov-24 11:35:57 -  INFO - create_service true\n",
      "26-Nov-24 11:35:57 -  INFO - [+] Created tracker Service True\n"
     ]
    }
   ],
   "source": [
    "# Create the application environment\n",
    "if env.get_env(\"LOCAL_DEPLOY\"):\n",
    "    await deployer_client.create_environment(\n",
    "        app=build_app,\n",
    "        scanflowEnv=data_sci_env\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3f0173",
   "metadata": {},
   "source": [
    "### Manual task: copy `scanflow` module\n",
    "This step copies this repository version of `scanflow` module inside the environment's PersistentVolumeClaim. The environment creation is done with asynchronous API calls, so we must ensure that both the `namespace` and the `persistentVolumeClaim` are already available before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7206cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jolivera/miniconda3/envs/dataconnector/lib/python3.11/site-packages/urllib3/connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host '84.88.189.179'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jolivera/miniconda3/envs/dataconnector/lib/python3.11/site-packages/urllib3/connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host '84.88.189.179'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking if persistentVolumeClaim 'scanflow-scanflow-cloudedge-proactive-migration-experiment-datascience' exists in namespace 'scanflow-cloudedge-proactive-migration-experiment-datascience'...\n",
      "PersistentVolumeClaim 'scanflow-scanflow-cloudedge-proactive-migration-experiment-datascience' is Bound and ready.\n",
      "Creating pod: cloudedge-debug-pod in namespace: scanflow-cloudedge-proactive-migration-experiment-datascience\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jolivera/miniconda3/envs/dataconnector/lib/python3.11/site-packages/urllib3/connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host '84.88.189.179'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pod 'cloudedge-debug-pod' is currently in phase: Pending\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jolivera/miniconda3/envs/dataconnector/lib/python3.11/site-packages/urllib3/connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host '84.88.189.179'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pod 'cloudedge-debug-pod' is currently in phase: Running\n",
      "Pod 'cloudedge-debug-pod' is now in Running state.\n"
     ]
    }
   ],
   "source": [
    "# Steps:\n",
    "# - Local variables:\n",
    "debug_pod_yaml = os.path.join(env.get_env(\"WORKDIR\"), \"tutorials\", \"cloudedge-proactive-migration\", \"debug_pod.yaml\")\n",
    "persistent_volume_claim = f\"scanflow-{environment_namespace}\"\n",
    "scanflow_folder = pathlib.Path(os.path.join(env.get_env(\"WORKDIR\"), \"scanflow\"))\n",
    "\n",
    "# - Check that the persistentVolumeClaim is properly Bound\n",
    "while not check_if_object_exists_and_ready(\n",
    "    client=kube_client,\n",
    "    object_type=\"persistentVolumeClaim\",\n",
    "    name=persistent_volume_claim,\n",
    "    namespace=environment_namespace\n",
    "):\n",
    "    # Wait 2 seconds for the next check\n",
    "    sleep(2)\n",
    "\n",
    "# - Deploy a Pod in the environment namespace that mounts the environment's persistentVolumeClaim.\n",
    "#   For now we'll provide a YAML file with the expected name of the PVC, but in the future\n",
    "#   this should be provided either by the ScanflowDeployClient or a Kubernetes API call\n",
    "deploy_pod_and_wait(\n",
    "    client=kube_client,\n",
    "    yaml_file=debug_pod_yaml,\n",
    "    namespace=environment_namespace\n",
    ")\n",
    "\n",
    "# - Once the pod is Running, proceed to compress the `scanflow` folder onto a tar file; then send it to the Pod\n",
    "#   and uncompress it at the destination path\n",
    "copy_local_path_to_pod(\n",
    "    client=kube_client,\n",
    "    namespace=environment_namespace,\n",
    "    pod_name=\"cloudedge-debug-pod\",\n",
    "    local_path=scanflow_folder,\n",
    "    dest_path=\"/scanflow/scanflow\",\n",
    "    exclude_paths=[\"__pycache__\"]\n",
    ")\n",
    "\n",
    "# - We can leave the Pod running for debugging purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e45d2d",
   "metadata": {},
   "source": [
    "## Run Workflow to test\n",
    "This composes an Argo CronWorkflow for the application and submits it to the Argo Workflows engine:\n",
    "- Pre-requisites: Argo Workflows must be set to use the `default` service account when no `serviceAccount` is provided in the template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e346cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26-Nov-24 11:36:07 -  INFO - [++] Running workflow: [proactive-training-datascience].\n",
      "26-Nov-24 11:36:07 -  INFO - [+] output dir /workflow\n",
      "26-Nov-24 11:36:07 -  INFO - [+] Create proactive-training-datascience output PVC\n",
      "/home/jolivera/miniconda3/envs/dataconnector/lib/python3.11/site-packages/urllib3/connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host '84.88.189.179'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "26-Nov-24 11:36:07 -  INFO - create_pvc true\n",
      "26-Nov-24 11:36:07 -  INFO - output dir created\n",
      "26-Nov-24 11:36:07 -  INFO - env for executor {'AWS_ACCESS_KEY_ID': 'scanflow', 'AWS_SECRET_ACCESS_KEY': 'scanflow123', 'MLFLOW_S3_ENDPOINT_URL': 'http://84.88.189.179:32645', 'AWS_ENDPOINT_URL': None, 'SCANFLOW_TRACKER_URI': 'http://84.88.189.179:32767', 'SCANFLOW_SERVER_URI': 'http://84.88.189.179:32767', 'SCANFLOW_TRACKER_LOCAL_URI': 'http://84.88.189.179:32767'}\n",
      "26-Nov-24 11:36:07 -  INFO - [+] Building workflow: [proactive-training-datascience:modeling].\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m env\u001b[38;5;241m.\u001b[39mget_env(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLOCAL_DEPLOY\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mawait\u001b[39;00m deployer_client\u001b[38;5;241m.\u001b[39mrun_app(app\u001b[38;5;241m=\u001b[39mbuild_app)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# DEBUG - TODO: if using external config files, automate their copy inside the workflow PVC instead of doing it manually\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# - Copy Promcsv config file so it is available within the container in the /workflow/promql_queries.json path\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/CloudSkin/Scanflow/data-connector/tutorials/cloudedge-proactive-migration/../../scanflow/client/scanflowDeployerClient.py:201\u001b[0m, in \u001b[0;36mScanflowDeployerClient.run_app\u001b[0;34m(self, app)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;66;03m#local\u001b[39;00m\n\u001b[1;32m    200\u001b[0m     namespace \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscanflow-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mapp\u001b[38;5;241m.\u001b[39mapp_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mapp\u001b[38;5;241m.\u001b[39mteam_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeployerbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_workflows\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mworkflows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscanflowEnv\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/CloudSkin/Scanflow/data-connector/tutorials/cloudedge-proactive-migration/../../scanflow/deployer/argoDeployer.py:40\u001b[0m, in \u001b[0;36mArgoDeployer.run_workflows\u001b[0;34m(self, namespace, workflows, scanflow_env)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m workflow\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     39\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[++] Running workflow: [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mworkflow\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m].\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 40\u001b[0m     submitted \u001b[38;5;241m=\u001b[39m submitted \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_workflow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnamespace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43mworkflow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkflow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscanflow_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscanflow_env\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[+] Workflow: [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mworkflow\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] was run successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Documents/CloudSkin/Scanflow/data-connector/tutorials/cloudedge-proactive-migration/../../scanflow/deployer/argoDeployer.py:136\u001b[0m, in \u001b[0;36mArgoDeployer.run_workflow\u001b[0;34m(self, namespace, workflow, scanflow_env)\u001b[0m\n\u001b[1;32m    126\u001b[0m     argoContainers[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexecutor\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margoclient\u001b[38;5;241m.\u001b[39margoExecutor(name \u001b[38;5;241m=\u001b[39m executor\u001b[38;5;241m.\u001b[39mname, \n\u001b[1;32m    127\u001b[0m              image \u001b[38;5;241m=\u001b[39m executor\u001b[38;5;241m.\u001b[39mimage,\n\u001b[1;32m    128\u001b[0m              image_pull_policy \u001b[38;5;241m=\u001b[39m executor\u001b[38;5;241m.\u001b[39mimage_pull_policy,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    133\u001b[0m              volumeMounts \u001b[38;5;241m=\u001b[39m volumeMounts,\n\u001b[1;32m    134\u001b[0m              resources \u001b[38;5;241m=\u001b[39m executor\u001b[38;5;241m.\u001b[39mresources\u001b[38;5;241m.\u001b[39mto_dict()\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlimits\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 136\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m parameters: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mformat_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    137\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m command: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mformat_command({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;250m \u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/app/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexecutor\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexecutor\u001b[38;5;241m.\u001b[39mmainfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m})\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    138\u001b[0m     argoContainers[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexecutor\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margoclient\u001b[38;5;241m.\u001b[39margoExecutor(name \u001b[38;5;241m=\u001b[39m executor\u001b[38;5;241m.\u001b[39mname, \n\u001b[1;32m    139\u001b[0m              image \u001b[38;5;241m=\u001b[39m executor\u001b[38;5;241m.\u001b[39mimage,\n\u001b[1;32m    140\u001b[0m              image_pull_policy \u001b[38;5;241m=\u001b[39m executor\u001b[38;5;241m.\u001b[39mimage_pull_policy,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    145\u001b[0m              volumeMounts \u001b[38;5;241m=\u001b[39m volumeMounts,\n\u001b[1;32m    146\u001b[0m              resources\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/CloudSkin/Scanflow/data-connector/tutorials/cloudedge-proactive-migration/../../scanflow/tools/param.py:3\u001b[0m, in \u001b[0;36mformat_parameters\u001b[0;34m(params)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat_parameters\u001b[39m(params: \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m      2\u001b[0m     list_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m():\n\u001b[1;32m      4\u001b[0m         list_params\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m         list_params\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "if env.get_env(\"LOCAL_DEPLOY\"):\n",
    "    await deployer_client.run_app(app=build_app)\n",
    "    # DEBUG - TODO: if using external config files, automate their copy inside the workflow PVC instead of doing it manually\n",
    "    # - Copy Promcsv config file so it is available within the container in the /workflow/promql_queries.json path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e53c37",
   "metadata": {},
   "source": [
    "## Clean-up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd27685",
   "metadata": {},
   "source": [
    "### Remove Scanflow application\n",
    "This will delete the target Scanflow application:\n",
    "- Remove its Argo Workflow object\n",
    "  - Currently not working as Workflow names or CronWorkflow names don't match the generated ones by `couler`\n",
    "- Remove its PVC and related PV (created during Argo Workflow execution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20fdf3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jolivera/miniconda3/envs/dataconnector/lib/python3.11/site-packages/urllib3/connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host '84.88.189.179'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "25-Nov-24 18:31:48 -  INFO - cannot find workflows\n",
      "/home/jolivera/miniconda3/envs/dataconnector/lib/python3.11/site-packages/urllib3/connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host '84.88.189.179'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "25-Nov-24 18:31:49 -  INFO - delete_pvc true\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jolivera/miniconda3/envs/dataconnector/lib/python3.11/site-packages/urllib3/connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host '84.88.189.179'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "25-Nov-24 18:31:49 -  ERROR - delete_pv error\n"
     ]
    }
   ],
   "source": [
    "# if env.get_env(\"LOCAL_DEPLOY\"):\n",
    "#     await deployer_client.delete_app(app=build_app)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fd0d1f",
   "metadata": {},
   "source": [
    "### Remove Scanflow environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6c383a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25-Nov-24 18:31:57 -  INFO - [++] Stopping agent: [planner].\n",
      "/home/jolivera/miniconda3/envs/dataconnector/lib/python3.11/site-packages/urllib3/connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host '84.88.189.179'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "25-Nov-24 18:31:57 -  INFO - delete_deployment true\n",
      "/home/jolivera/miniconda3/envs/dataconnector/lib/python3.11/site-packages/urllib3/connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host '84.88.189.179'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "25-Nov-24 18:31:57 -  INFO - delete_service true\n",
      "25-Nov-24 18:31:57 -  INFO - [++] Stopping tracker: [scanflow-tracker].\n",
      "/home/jolivera/miniconda3/envs/dataconnector/lib/python3.11/site-packages/urllib3/connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host '84.88.189.179'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "25-Nov-24 18:31:57 -  INFO - delete_deployment true\n",
      "/home/jolivera/miniconda3/envs/dataconnector/lib/python3.11/site-packages/urllib3/connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host '84.88.189.179'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "25-Nov-24 18:31:57 -  INFO - delete_service true\n",
      "25-Nov-24 18:31:57 -  INFO - [++]Delete tracker configmap scanflow-tracker-env\n",
      "/home/jolivera/miniconda3/envs/dataconnector/lib/python3.11/site-packages/urllib3/connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host '84.88.189.179'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "25-Nov-24 18:31:58 -  INFO - delete_configmap true\n",
      "25-Nov-24 18:31:58 -  INFO - [++]Delete client configmap scanflow-client-env\n",
      "/home/jolivera/miniconda3/envs/dataconnector/lib/python3.11/site-packages/urllib3/connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host '84.88.189.179'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "25-Nov-24 18:31:58 -  INFO - delete_configmap true\n",
      "25-Nov-24 18:31:58 -  INFO - [++]Delete s3 secret scanflow-secret\n",
      "/home/jolivera/miniconda3/envs/dataconnector/lib/python3.11/site-packages/urllib3/connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host '84.88.189.179'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "25-Nov-24 18:31:58 -  INFO - delete_secret true\n",
      "25-Nov-24 18:31:58 -  INFO - [++]Deleting Image Pull Secret cloudskin-registry\n",
      "/home/jolivera/miniconda3/envs/dataconnector/lib/python3.11/site-packages/urllib3/connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host '84.88.189.179'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "25-Nov-24 18:31:58 -  INFO - delete_secret true\n",
      "25-Nov-24 18:31:58 -  INFO - [++]Delete rolebinding default-admin\n",
      "/home/jolivera/miniconda3/envs/dataconnector/lib/python3.11/site-packages/urllib3/connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host '84.88.189.179'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "25-Nov-24 18:31:58 -  INFO - delete_rolebinding info\n",
      "25-Nov-24 18:31:58 -  INFO - [++]Delete namespace \"scanflow-cloudedge-proactive-migration-experiment-datascience\"\n",
      "/home/jolivera/miniconda3/envs/dataconnector/lib/python3.11/site-packages/urllib3/connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host '84.88.189.179'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "25-Nov-24 18:31:58 -  INFO - delete_namespace true\n",
      "/home/jolivera/miniconda3/envs/dataconnector/lib/python3.11/site-packages/urllib3/connectionpool.py:1064: InsecureRequestWarning: Unverified HTTPS request is being made to host '84.88.189.179'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/1.26.x/advanced-usage.html#ssl-warnings\n",
      "  warnings.warn(\n",
      "25-Nov-24 18:31:58 -  INFO - delete_pvc true\n"
     ]
    }
   ],
   "source": [
    "# if env.get_env(\"LOCAL_DEPLOY\"):\n",
    "#     await deployer_client.clean_environment(app=build_app, scanflow_env=data_eng_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc4d001",
   "metadata": {},
   "source": [
    "## MLFlow debug cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dacbcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if env.get_env(\"LOCAL_DEPLOY\"):\n",
    "#     import mlflow\n",
    "#     from scanflow.client import ScanflowTrackerClient\n",
    "\n",
    "#     client = ScanflowTrackerClient(scanflow_tracker_local_uri=env.get_env(\"SCANFLOW_TRACKER_URI\"))\n",
    "#     mlflow.set_tracking_uri(client.get_tracker_uri(True))\n",
    "#     # Retrieve the Application experiment\n",
    "    \n",
    "#     reactive_experiment = mlflow.get_experiment_by_name(app_name)\n",
    "#     experiment_id = reactive_experiment.experiment_id\n",
    "#     print(experiment_id)\n",
    "\n",
    "#     # Retrieve filtered experiment runs by run_name, ordered by descending end time --> First entry will be the most recent\n",
    "#     # runs_df = mlflow.search_runs([experiment_id], filter_string=f\"run_name='{team_name}'\", order_by=[\"end_time DESC\"])\n",
    "#     # run_id = runs_df.loc[[0]]['run_id'][0]\n",
    "#     # print(run_id)\n",
    "\n",
    "#     # Delete experiment\n",
    "#     #mlflow.delete_experiment(experiment_id=str(experiment_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2032efe9-b4a5-44ba-805e-bd2c86a11efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trackerClient = ScanflowTrackerClient(\n",
    "#                         scanflow_tracker_local_uri=\"http://84.88.189.179:32765\",\n",
    "#                         verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64aaee0b-3922-4d68-894a-8278995f6fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trackerClient.save_app_model(app_name=app_name,\n",
    "#                             team_name=team_name,\n",
    "#                             model_name=\"model_LSTM_a6050a48-03a9-4d02-927a-878317624b52.pt\",\n",
    "#                             model_version=\"1\")\n",
    "# trackerClient.save_app_model(app_name=app_name,\n",
    "#                             team_name=team_name,\n",
    "#                             model_name=\"model_LSTM_c2313dca-f464-4fe3-96c6-cdbe530fe89e.pt\",\n",
    "#                             model_version=\"1\")\n",
    "\n",
    "\n",
    "\n",
    "# # Saving scalers in order to normalize/denormalize for inference. These could potentially be artifacts if automated properly.\n",
    "# trackerClient.save_app_model(app_name=app_name,\n",
    "#                             team_name=team_name,\n",
    "#                             model_name=\"LSTM_scaler_x_a6050a48-03a9-4d02-927a-878317624b52\",\n",
    "#                             model_version=\"1\")\n",
    "# trackerClient.save_app_model(app_name=app_name,\n",
    "#                             team_name=team_name,\n",
    "#                             model_name=\"LSTM_scaler_y_a6050a48-03a9-4d02-927a-878317624b52\",\n",
    "#                             model_version=\"1\")\n",
    "\n",
    "# trackerClient.save_app_model(app_name=app_name,\n",
    "#                             team_name=team_name,\n",
    "#                             model_name=\"LSTM_scaler_x_c2313dca-f464-4fe3-96c6-cdbe530fe89e\",\n",
    "#                             model_version=\"1\")\n",
    "# trackerClient.save_app_model(app_name=app_name,\n",
    "#                             team_name=team_name,\n",
    "#                             model_name=\"LSTM_scaler_y_c2313dca-f464-4fe3-96c6-cdbe530fe89e\",\n",
    "#                             model_version=\"1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e334b8d6-c472-4443-9424-627e6632ab8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
