{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6acdbd28-a67a-41b4-b4e6-16e3a0a5626e",
   "metadata": {},
   "source": [
    "# CloudEdge DataEngineer (Inference Stage)\n",
    "\n",
    "****Inference Scenarios****\n",
    "\n",
    "| scenarios | reference app | framework | model/dataset |\n",
    "| ---- | ---- | ---- | ---- |\n",
    "| batch-inference-workflow | [scenarios/job-pipeline](https://github.com/peiniliu/inference/tree/dev/vision/classification_and_detection/scenarios/job-pipeline) | tensorflow | resnet/dumy |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b95d7f3-b42a-4c13-8902-e3ca6f2de632",
   "metadata": {},
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62f31ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only for debug purposes, don't enable and push them!!!\n",
    "#%env WORKDIR=/your/repository/root/path\n",
    "#%env REACTIVE_MIGRATION_DATAENGINEER_APP_DIR=examples/cloudedge-reactive-migration/dataengineer\n",
    "#%env SCANFLOW_SERVER_URI=http://10.17.252.5:32766\n",
    "#%env SCANFLOW_TRACKER_URI=http://10.17.252.5:32766\n",
    "#%env MLFLOW_S3_ENDPOINT_URI=http://10.17.252.5:32910\n",
    "#%env AWS_ACCESS_KEY_ID=admin\n",
    "#%env AWS_SECRET_ACCESS_KEY=scanflow123\n",
    "#%env DOCKER_REGISTRY=registry.gitlab.bsc.es/datacentric-computing/cloudskin-project/cloudskin-registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bca50738-a9da-45ec-97fa-9d1722b71dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0,'../..')\n",
    "\n",
    "from scanflow.client import ScanflowClient\n",
    "from scanflow.client import ScanflowTrackerClient\n",
    "from scanflow.client import ScanflowDeployerClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3ed2df1-257b-4bc5-a641-2d65a168dc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scanflow.tools import env\n",
    "print(env.get_env(\"SCANFLOW_SERVER_URI\"))\n",
    "print(env.get_env(\"SCANFLOW_TRACKER_URI\"))\n",
    "print(env.get_env(\"MLFLOW_S3_ENDPOINT_URL\"))\n",
    "print(env.get_env(\"AWS_ACCESS_KEY_ID\"))\n",
    "print(env.get_env(\"AWS_SECRET_ACCESS_KEY\"))\n",
    "print(env.get_env(\"DOCKER_REGISTRY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2eeae4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# App folder - Must point to the folder includeing all 'dataengineer' and 'datascience' folders\n",
    "# for cloudedge-reactive-migration, allocated in examples/cloudedge-reactive-migration\n",
    "app_dir = os.path.join(env.get_env('WORKDIR'), env.get_env('REACTIVE_MIGRATION_DATAENGINEER_APP_DIR'))\n",
    "print(app_dir)\n",
    "app_name = \"cloudedge-reactive-migration\"\n",
    "team_name = \"dataengineer\"\n",
    "\n",
    "# Initialize the Scanflow Client\n",
    "client = ScanflowClient(\n",
    "    #if you defined \"SCANFLOW_SERVER_URI\", you dont need to provide this\n",
    "    registry=env.get_env(\"DOCKER_REGISTRY\"),\n",
    "    verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dddf4c1",
   "metadata": {},
   "source": [
    "## Batch-inference-graph for prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497a7fd2",
   "metadata": {},
   "source": [
    "### Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9bfbbdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictor stages\n",
    "# - Executor 1: Data retrieval from Prometheus\n",
    "# - Executor 2: Data pre-processing\n",
    "# - Executor 3: QoS Predictor\n",
    "executor1 = client.ScanflowExecutor(\n",
    "    name=\"data-retrieval\",\n",
    "    mainfile=\"data-retrieval.py\",\n",
    "    parameters={\n",
    "        'app_name': app_name,\n",
    "        'team_name': team_name\n",
    "    }\n",
    ")\n",
    "\n",
    "# Stages dependencies\n",
    "# TODO: define them once other stages have been developed\n",
    "\n",
    "# Predictor workflow: batch-inference-reactive-graph\n",
    "# TODO: add missing executors and dependencies\n",
    "workflow1 = client.ScanflowWorkflow(\n",
    "    name=\"batch-inference-reactive-graph\",\n",
    "    nodes=[executor1],\n",
    "    edges=[],\n",
    "    type=\"batch\",\n",
    "    cron=\"*/5 * * * *\",\n",
    "    output_dir=\"/workflow\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e1117d",
   "metadata": {},
   "source": [
    "### Planner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "077d38a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "trigger = client.ScanflowAgentSensor_IntervalTrigger(minutes=5)\n",
    "sensor = client.ScanflowAgentSensor(\n",
    "    name=\"reactive_watch_qos\",\n",
    "    isCustom=True,\n",
    "    func_name=\"reactive_watch_qos\",\n",
    "    trigger=trigger,\n",
    "    kwargs={\n",
    "        'frequency': 300\n",
    "    }\n",
    ")\n",
    "planner = client.ScanflowAgent(\n",
    "    name=\"planner\",\n",
    "    template=\"planner\",\n",
    "    sensors=[sensor]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f83129",
   "metadata": {},
   "source": [
    "### Compose the Scanflow Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b9fd7229",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = client.ScanflowApplication(\n",
    "    app_name=app_name,\n",
    "    app_dir=app_dir,\n",
    "    team_name=team_name,\n",
    "    workflows=[workflow1],\n",
    "    agents=[planner]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812ed3b3",
   "metadata": {},
   "source": [
    "### DEBUG: show application config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d6133549",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f339ddc6",
   "metadata": {},
   "source": [
    "### Build the Scanflow Application\n",
    "- This step builds the Docker images for all the Scanflow executors and uploads them to the container registry (currently hardcoded in the `scanflow` module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89df89b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Scanflow Tracker Port (32766)\n",
    "build_app = client.build_ScanflowApplication(\n",
    "    app=app,\n",
    "    trackerPort=32766\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843d71d4",
   "metadata": {},
   "source": [
    "### DEBUG: show built application config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad6d14e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "build_app.to_dict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
